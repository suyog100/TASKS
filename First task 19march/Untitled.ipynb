{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "eae27f05",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import json\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6e27efa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Base URLs\n",
    "base_url = \"https://m.freightbook.net/\"\n",
    "country_url = \"https://m.freightbook.net/member/results?country={}\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a9060058",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Headers to mimic a browser request\n",
    "headers = {\n",
    "    \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/122.0.0.0 Safari/537.36\"\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6733f01c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to extract country IDs from the dropdown\n",
    "def get_country_ids():\n",
    "    response = requests.get(base_url, headers=headers)\n",
    "    if response.status_code != 200:\n",
    "        print(\"Failed to fetch country list\")\n",
    "        return {}\n",
    "\n",
    "    soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "    country_options = soup.select(\"select option\")  # Extract dropdown options\n",
    "\n",
    "    country_list = {}\n",
    "    for option in country_options:\n",
    "        if option.get(\"value\") and option.text.strip():\n",
    "            country_list[option.text.strip()] = option[\"value\"]\n",
    "\n",
    "    return country_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b79be869",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to scrape companies from a given country\n",
    "def scrape_country_forwarders(country_name, country_id):\n",
    "    url = country_url.format(country_id)\n",
    "    response = requests.get(url, headers=headers)\n",
    "    if response.status_code != 200:\n",
    "        print(f\"Failed to fetch companies for {country_name}\")\n",
    "        return []\n",
    "\n",
    "    soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "    forwarders = []\n",
    "\n",
    "    # Locate all company blocks\n",
    "    company_blocks = soup.find_all(\"div\", class_=\"company-box\")  # Adjust class if needed\n",
    "\n",
    "    for company in company_blocks:\n",
    "        try:\n",
    "            name = company.find(\"a\").text.strip() if company.find(\"a\") else \"N/A\"\n",
    "            profile_link = company.find(\"a\")[\"href\"] if company.find(\"a\") else None\n",
    "            address = company.find(\"p\", class_=\"address\").text.strip() if company.find(\"p\", class_=\"address\") else \"N/A\"\n",
    "            country = company.find(\"p\", class_=\"country\").text.strip() if company.find(\"p\", class_=\"country\") else \"N/A\"\n",
    "\n",
    "            # If profile link exists, fetch detailed data\n",
    "            full_details = scrape_company_details(profile_link) if profile_link else {}\n",
    "\n",
    "            forwarders.append({\n",
    "                \"Company Name\": name,\n",
    "                \"Address\": address,\n",
    "                \"Country\": country,\n",
    "                \"Profile Link\": base_url + profile_link if profile_link else \"N/A\",\n",
    "                **full_details  # Merge detailed data if available\n",
    "            })\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error extracting company details: {e}\")\n",
    "\n",
    "    return forwarders\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "447932ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to extract details from company profile pages\n",
    "def scrape_company_details(profile_link):\n",
    "    url = base_url + profile_link\n",
    "    response = requests.get(url, headers=headers)\n",
    "    if response.status_code != 200:\n",
    "        print(f\"Failed to fetch company details for {url}\")\n",
    "        return {}\n",
    "\n",
    "    soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "\n",
    "    details = {}\n",
    "    try:\n",
    "        details[\"Telephone\"] = soup.find(\"p\", class_=\"tel\").text.strip() if soup.find(\"p\", class_=\"tel\") else \"N/A\"\n",
    "        details[\"Year Business Started\"] = soup.find(text=\"Year Business Started:\").find_next().text.strip() if soup.find(text=\"Year Business Started:\") else \"N/A\"\n",
    "        details[\"Owner\"] = soup.find(text=\"Owner\").find_next().text.strip() if soup.find(text=\"Owner\") else \"N/A\"\n",
    "        details[\"Services\"] = [s.text.strip() for s in soup.find_all(\"li\")]  # Extracts all listed services\n",
    "        details[\"IATA Member\"] = soup.find(text=\"IATA Member\").find_next().text.strip() if soup.find(text=\"IATA Member\") else \"N/A\"\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error extracting details: {e}\")\n",
    "\n",
    "    return details\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3bb88c02",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scraping Search by country......\n",
      "Scraping AFGHANISTAN...\n",
      "Scraping ARGENTINA...\n",
      "Scraping ARMENIA...\n",
      "Scraping AUSTRALIA...\n",
      "Scraping AZERBAIJAN...\n",
      "Scraping BAHRAIN...\n",
      "Scraping BANGLADESH...\n",
      "Scraping BELARUS...\n",
      "Scraping BELGIUM...\n",
      "Scraping BENIN...\n",
      "Scraping BRAZIL...\n",
      "Scraping BULGARIA...\n",
      "Scraping CAMBODIA...\n",
      "Scraping CAMEROON...\n",
      "Scraping CANADA...\n",
      "Scraping CHILE...\n",
      "Scraping CHINA...\n",
      "Scraping COLOMBIA...\n",
      "Scraping CONGO, DEMOCRATIC REPUBLIC...\n",
      "Scraping COSTA RICA...\n",
      "Scraping COTE D IVOIRE...\n",
      "Scraping CYPRUS...\n",
      "Scraping CZECH REPUBLIC...\n",
      "Scraping DENMARK...\n",
      "Scraping DOMINICAN REPUBLIC...\n",
      "Scraping ECUADOR...\n",
      "Scraping EGYPT...\n",
      "Scraping EL SALVADOR...\n",
      "Scraping EQUATORIAL GUINEA...\n",
      "Scraping ESTONIA...\n",
      "Scraping FRANCE...\n",
      "Scraping GEORGIA...\n",
      "Scraping GERMANY...\n",
      "Scraping GHANA...\n",
      "Scraping GIBRALTAR...\n",
      "Scraping GREECE...\n",
      "Scraping GUATEMALA...\n",
      "Scraping HAITI...\n",
      "Scraping HONDURAS...\n",
      "Scraping HONG KONG...\n",
      "Scraping HUNGARY...\n",
      "Scraping INDIA...\n",
      "Scraping INDONESIA...\n",
      "Scraping IRAQ...\n",
      "Scraping IRELAND...\n",
      "Scraping ISRAEL...\n",
      "Scraping ITALY...\n",
      "Scraping JAMAICA...\n",
      "Scraping JORDAN...\n",
      "Scraping KAZAKHSTAN...\n",
      "Scraping KENYA...\n",
      "Scraping KUWAIT...\n",
      "Scraping KYRGYZSTAN...\n",
      "Scraping LAOS...\n",
      "Scraping LATVIA...\n",
      "Scraping LEBANON...\n",
      "Scraping LITHUANIA...\n",
      "Scraping MALAYSIA...\n",
      "Scraping MALDIVES...\n",
      "Scraping MALI...\n",
      "Scraping MALTA...\n",
      "Scraping MAURITANIA...\n",
      "Scraping MAURITIUS...\n",
      "Scraping MEXICO...\n",
      "Scraping MICRONESIA, FEDERATED STATES OF...\n",
      "Scraping MOLDOVA...\n",
      "Scraping MONGOLIA...\n",
      "Scraping MOROCCO...\n",
      "Scraping MYANMAR...\n",
      "Scraping NEPAL...\n",
      "Scraping NETHERLANDS...\n",
      "Scraping NEW ZEALAND...\n",
      "Scraping NICARAGUA...\n",
      "Scraping NIGERIA...\n",
      "Scraping OMAN...\n",
      "Scraping PAKISTAN...\n",
      "Scraping PANAMA...\n",
      "Scraping PERU...\n",
      "Scraping PHILIPPINES...\n",
      "Scraping POLAND...\n",
      "Scraping PORTUGAL...\n",
      "Scraping QATAR...\n",
      "Scraping ROMANIA...\n",
      "Scraping RWANDA...\n",
      "Scraping SAUDI ARABIA...\n",
      "Scraping SENEGAL...\n",
      "Scraping SERBIA...\n",
      "Scraping SINGAPORE...\n",
      "Scraping SLOVENIA...\n",
      "Scraping SOUTH AFRICA...\n",
      "Scraping SOUTH KOREA...\n",
      "Scraping SPAIN...\n",
      "Scraping SRI LANKA...\n",
      "Scraping SWITZERLAND...\n",
      "Scraping TAIWAN...\n",
      "Scraping TANZANIA...\n",
      "Scraping THAILAND...\n",
      "Scraping TOGO...\n",
      "Scraping TRINIDAD AND TOBAGO...\n",
      "Scraping TUNISIA...\n",
      "Scraping TURKEY...\n",
      "Scraping UKRAINE...\n",
      "Scraping UNITED ARAB EMIRATES...\n",
      "Scraping UNITED KINGDOM...\n",
      "Scraping UNITED STATES...\n",
      "Scraping URUGUAY...\n",
      "Scraping VENEZUELA...\n",
      "Scraping VIETNAM...\n",
      "Scraping ZIMBABWE...\n",
      "Scraping completed. Data saved in freightbook_data.json\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    country_ids = get_country_ids()\n",
    "    \n",
    "    all_data = {}\n",
    "    for country, country_id in country_ids.items():\n",
    "        print(f\"Scraping {country}...\")\n",
    "        country_data = scrape_country_forwarders(country, country_id)\n",
    "        all_data[country] = country_data\n",
    "        time.sleep(3)  # Avoid too many requests quickly\n",
    "\n",
    "    # Save data to JSON file\n",
    "    output_file = \"freightbook_data.json\"\n",
    "    with open(output_file, \"w\", encoding=\"utf-8\") as json_file:\n",
    "        json.dump(all_data, json_file, indent=4, ensure_ascii=False)\n",
    "\n",
    "    print(f\"Scraping completed. Data saved in {output_file}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "173d31d5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
